# Applio TTS Inference API

API REST para gera√ß√£o de √°udio usando Text-to-Speech (TTS) com Voice Conversion (RVC) do Applio.

## üöÄ In√≠cio R√°pido

### Instala√ß√£o

1. Instale as depend√™ncias:
```bash
pip install -r requirements.txt
```

2. Configure as vari√°veis de ambiente (opcional):
```bash
# Crie um arquivo .env na pasta api/ (veja README_CONFIG.md para detalhes)
# Ou use vari√°veis de ambiente diretamente
export PYANNOTE_TOKEN=seu_token_huggingface  # Opcional, s√≥ para diariza√ß√£o
```

3. Inicie a API:
```bash
# Usando o script
./start.sh

# Ou diretamente com Python
python app.py

# Ou com uvicorn
uvicorn app:app --host 0.0.0.0 --port 8000
```

### ‚öôÔ∏è Configura√ß√£o

Para mais detalhes sobre configura√ß√£o, veja [README_CONFIG.md](./README_CONFIG.md).

As principais configura√ß√µes:
- **Whisper**: Modelo de transcri√ß√£o (padr√£o: `turbo`)
- **Pyannote**: Token do Hugging Face para diariza√ß√£o (opcional)
- **API**: Host e porta (padr√£o: `0.0.0.0:8000`)

### Acessar Documenta√ß√£o

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## üì° Endpoints

### Informa√ß√µes

- `GET /` - Informa√ß√µes da API
- `GET /health` - Health check

### TTS (Text-to-Speech)

- `GET /voices` - Lista todas as vozes TTS dispon√≠veis (Edge TTS)
- `POST /tts/generate` - Gera √°udio usando TTS + RVC (vers√£o simplificada)
- `POST /tts/inference` - Gera √°udio usando TTS + RVC (vers√£o completa)
- `GET /tts/download/{filename}` - Download de arquivo de √°udio gerado

### Transcription (Transcri√ß√£o)

- `POST /transcribe` - Transcreve √°udio usando Whisper V3 Turbo + Pyannote diarization

### RVC (Retrieval-Based Voice Conversion)

- `GET /models` - Lista todos os modelos RVC dispon√≠veis

## üìù Exemplos de Uso

### Listar Vozes Dispon√≠veis

```bash
curl http://localhost:8000/voices
```

Com filtro de idioma:
```bash
curl "http://localhost:8000/voices?language=pt-BR"
```

### Listar Modelos RVC

```bash
curl http://localhost:8000/models
```

### Gerar √Åudio TTS + RVC

```bash
curl -X POST "http://localhost:8000/tts/inference" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Ol√°, este √© um teste de s√≠ntese de voz.",
    "tts_voice": "pt-BR-FranciscaNeural",
    "model_path": "logs/modelo_exemplo/modelo.pth",
    "index_path": "logs/modelo_exemplo/modelo.index",
    "pitch": 0,
    "index_rate": 0.75,
    "export_format": "WAV"
  }'
```

### Gerar √Åudio e Receber em Base64

```bash
curl -X POST "http://localhost:8000/tts/generate" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Ol√°, este √© um teste de s√≠ntese de voz.",
    "tts_voice": "pt-BR-FranciscaNeural",
    "model_path": "logs/modelo_exemplo/modelo.pth",
    "output_format": "OGG"
  }'
```

### Transcrever √Åudio com Diariza√ß√£o

```bash
curl -X POST "http://localhost:8000/transcribe" \
  -F "file=@audio.mp3" \
  -F "language=pt" \
  -F "enable_diarization=true" \
  -F "model_size=turbo"
```

## üîß Par√¢metros de TTS Inference

### Obrigat√≥rios

- `text`: Texto para sintetizar (1-5000 caracteres)
- `tts_voice`: Voz TTS (ShortName da voz Edge TTS)
- `model_path`: Caminho do modelo RVC (.pth)

### Opcionais

#### TTS
- `tts_rate`: Taxa de velocidade (-100 a 100, padr√£o: 0)
- `index_path`: Caminho do arquivo index (auto-detectado se n√£o fornecido)

#### RVC
- `pitch`: Pitch do √°udio (-24 a 24, padr√£o: 0)
- `index_rate`: Taxa de influ√™ncia do index (0.0 a 1.0, padr√£o: 0.75)
- `volume_envelope`: Volume envelope (0.0 a 1.0, padr√£o: 1.0)
- `protect`: Prote√ß√£o de consoantes sem voz (0.0 a 0.5, padr√£o: 0.5)
- `f0_method`: M√©todo de extra√ß√£o de pitch (crepe, crepe-tiny, rmvpe, fcpe, padr√£o: rmvpe)

#### Avan√ßados
- `split_audio`: Dividir √°udio em chunks (padr√£o: false)
- `f0_autotune`: Aplicar autotune (padr√£o: false)
- `f0_autotune_strength`: For√ßa do autotune (0.0 a 1.0, padr√£o: 1.0)
- `proposed_pitch`: Ajustar pitch proposto (padr√£o: false)
- `proposed_pitch_threshold`: Threshold do pitch proposto (50.0 a 1200.0, padr√£o: 155.0)
- `clean_audio`: Limpar √°udio (padr√£o: false)
- `clean_strength`: For√ßa da limpeza (0.0 a 1.0, padr√£o: 0.5)
- `export_format`: Formato de exporta√ß√£o (WAV, MP3, FLAC, OGG, M4A, padr√£o: WAV)
- `embedder_model`: Modelo embedder (contentvec, spin, spin-v2, etc., padr√£o: contentvec)
- `embedder_model_custom`: Caminho do embedder customizado (se embedder_model='custom')
- `sid`: Speaker ID (padr√£o: 0)

#### Sa√≠da
- `return_base64`: Retornar √°udio em base64 (padr√£o: false)
- `output_filename`: Nome do arquivo de sa√≠da (opcional)

## üêç Exemplo Python

```python
import requests
import base64

# URL da API
API_URL = "http://localhost:8000"

# Listar vozes
response = requests.get(f"{API_URL}/voices")
voices = response.json()
print(f"Vozes dispon√≠veis: {voices['total']}")

# Listar modelos
response = requests.get(f"{API_URL}/models")
models = response.json()
print(f"Modelos dispon√≠veis: {models['total']}")

# Gerar √°udio
payload = {
    "text": "Ol√°, este √© um teste de s√≠ntese de voz.",
    "tts_voice": "pt-BR-FranciscaNeural",
    "model_path": "logs/modelo_exemplo/modelo.pth",
    "return_base64": True
}

response = requests.post(f"{API_URL}/tts/inference", json=payload)
result = response.json()

if result["success"]:
    # Salvar √°udio de base64
    if result["base64"]:
        audio_data = base64.b64decode(result["base64"])
        with open("output.wav", "wb") as f:
            f.write(audio_data)
        print(f"√Åudio salvo: output.wav")
    else:
        print(f"Arquivo gerado: {result['output_path']}")
else:
    print(f"Erro: {result['message']}")
```

## üîç Vari√°veis de Ambiente

Voc√™ pode configurar a API usando vari√°veis de ambiente:

```bash
export HOST=0.0.0.0
export PORT=8000
export RELOAD=true  # Para desenvolvimento
```

## üé§ Transcri√ß√£o de √Åudio

### Endpoint `/transcribe`

Transcreve √°udio usando **Whisper V3 Turbo** (modelo mais moderno) com **Pyannote diarization** para identificar diferentes speakers.

#### Par√¢metros

- `file` (obrigat√≥rio): Arquivo de √°udio para transcrever
- `language` (opcional): Idioma do √°udio (pt, en, es, etc.) ou 'auto' para detec√ß√£o autom√°tica (padr√£o: pt)
- `enable_diarization` (opcional): Ativar diariza√ß√£o para identificar speakers (padr√£o: true)
- `word_timestamps` (opcional): Incluir timestamps por palavra (padr√£o: false)
- `model_size` (opcional): Tamanho do modelo Whisper - turbo, large-v3, large, medium, small, base, tiny (padr√£o: turbo)

#### Formatos Suportados

MP3, WAV, M4A, FLAC, OGG, WEBM, MP4, AAC

#### Exemplo de Resposta

```json
{
  "success": true,
  "message": "‚úÖ √Åudio transcrito com sucesso (com diariza√ß√£o)",
  "text": "Ol√°, este √© um teste de transcri√ß√£o com diariza√ß√£o.",
  "language": "pt",
  "duration": 5.2,
  "speakers": ["SPEAKER_00", "SPEAKER_01"],
  "segments": [
    {
      "speaker": "SPEAKER_00",
      "start": 0.0,
      "end": 2.5,
      "text": "Ol√°, este √© um teste"
    },
    {
      "speaker": "SPEAKER_01",
      "start": 2.5,
      "end": 5.2,
      "text": "de transcri√ß√£o com diariza√ß√£o."
    }
  ]
}
```

### Configura√ß√£o do Pyannote

Para usar diariza√ß√£o, voc√™ precisa de um token do Hugging Face:

1. Crie uma conta no [Hugging Face](https://huggingface.co/)
2. Aceite os termos do modelo [pyannote/speaker-diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1)
3. Gere um token em [Settings > Access Tokens](https://huggingface.co/settings/tokens)
3. Configure a vari√°vel de ambiente:

```bash
export PYANNOTE_TOKEN=seu_token_aqui
```

**Nota:** Se o token n√£o estiver configurado, a transcri√ß√£o funcionar√° normalmente, mas sem diariza√ß√£o.

## üìã Requisitos

- Python 3.8+
- Applio instalado e configurado
- Modelos RVC treinados (em `logs/`)
- Depend√™ncias do Applio instaladas
- Whisper V3 Turbo (instalado automaticamente via requirements.txt)
- Pyannote.audio (instalado automaticamente via requirements.txt)

## üõ†Ô∏è Troubleshooting

### Erro: "Modelo n√£o encontrado"
- Verifique se o caminho do modelo est√° correto
- Use `/models` para listar modelos dispon√≠veis

### Erro: "Voz TTS n√£o encontrada"
- Use `/voices` para listar vozes dispon√≠veis
- Use o `ShortName` da voz (ex: "pt-BR-FranciscaNeural")

### Erro: "Arquivo index n√£o encontrado"
- O index pode ser auto-detectado se n√£o fornecido
- Verifique se o index est√° no mesmo diret√≥rio do modelo

## üìö Documenta√ß√£o Adicional

- [Applio Documentation](https://docs.applio.org)
- [Edge TTS Voices](https://speech.platform.bing.com/consumer/speech/synthesize/readaloud/voices/list)

## üìÑ Licen√ßa

Consulte o arquivo LICENSE do projeto Applio.

